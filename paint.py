import torch
import streamlit as st
from diffusers import StableDiffusionPipeline
from transformers import MarianMTModel, MarianTokenizer
from PIL import Image

# ------------------ æ¨¡å‹åŠ è½½ ------------------
@st.cache_resource
def load_sd_pipeline():
    model_id = "stabilityai/stable-diffusion-2-1-base"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    pipe = StableDiffusionPipeline.from_pretrained(model_id).to(device)
    return pipe, device

@st.cache_resource
def load_translator():
    model_name = "Helsinki-NLP/opus-mt-zh-en"
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    model = MarianMTModel.from_pretrained(model_name)
    return tokenizer, model

pipe, device = load_sd_pipeline()
tokenizer, translator_model = load_translator()

# ------------------ ä¸­æ–‡è½¬è‹±æ–‡å‡½æ•° ------------------
def translate_zh2en(text):
    batch = tokenizer.prepare_seq2seq_batch([text], return_tensors="pt")
    gen = translator_model.generate(**batch, max_length=100)
    translated = tokenizer.batch_decode(gen, skip_special_tokens=True)[0]
    return translated

# ------------------ é¡µé¢è®¾ç½® ------------------
st.set_page_config(page_title="ğŸ¨çµé­‚ç”»æ‰‹", layout="centered")
st.title("ğŸ§ çµé­‚ç”»æ‰‹")

st.markdown("è¾“å…¥ä¸­æ–‡æç¤ºè¯ï¼Œçµé­‚ç”»æ‰‹å¼€å§‹ä½œç”» ğŸ“·")

# ------------------ ç”¨æˆ·è¾“å…¥ ------------------
prompt_zh = st.text_input("ğŸ“ ä½ å¸Œæœ›ç”»ä»€ä¹ˆï¼Ÿ", value="ä¸€åªçŒ«åœ¨çœ‹æ˜Ÿç©º")
negative_zh = st.text_input("ğŸš« ä¸å¸Œæœ›å‡ºç°çš„å†…å®¹", value="æ¨¡ç³Šã€ä½è´¨é‡")
steps = st.slider("ğŸ¨ ç”»å›¾ç²¾è‡´åº¦", 10, 50, 30)
guidance = st.slider("ğŸ“¢ æè¿°å½±å“å¼ºåº¦", 1.0, 15.0, 7.5)
width = st.slider("ğŸ–¼ï¸ å›¾ç‰‡å®½åº¦ï¼ˆåƒç´ ï¼‰", 256, 768, 512, step=64)
height = st.slider("ğŸ–¼ï¸ å›¾ç‰‡é«˜åº¦ï¼ˆåƒç´ ï¼‰", 256, 768, 512, step=64)

# ------------------ ç”ŸæˆæŒ‰é’® ------------------
if st.button("ğŸ¨ ç”Ÿæˆå›¾ç‰‡"):
    with st.spinner("â³çµé­‚ç”»æ‰‹æ­£åœ¨ç»˜åˆ¶ï¼Œè¯·ç¨å€™..."):
        prompt_en = translate_zh2en(prompt_zh)
        negative_en = translate_zh2en(negative_zh)
        generator = torch.Generator(device=device).manual_seed(42)
        output = pipe(
            prompt=prompt_en,
            negative_prompt=negative_en,
            width=width,
            height=height,
            guidance_scale=guidance,
            num_inference_steps=steps,
            generator=generator
        )
        image = output.images[0]
        st.image(image, use_column_width=True)
